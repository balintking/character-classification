{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10013777,"sourceType":"datasetVersion","datasetId":6165120}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!pip install git+https://github.com/adriangb/scikeras.git -q ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!pip install tensorflow==2.7.0\n!pip install scikeras","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T22:23:07.013444Z","iopub.execute_input":"2024-11-26T22:23:07.014119Z","iopub.status.idle":"2024-11-26T22:23:19.922335Z","shell.execute_reply.started":"2024-11-26T22:23:07.014085Z","shell.execute_reply":"2024-11-26T22:23:19.921103Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\t\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\nfrom scikeras.wrappers import KerasClassifier\n\nimport keras\nfrom keras import layers","metadata":{"ExecuteTime":{"end_time":"2024-11-26T00:07:44.914596Z","start_time":"2024-11-26T00:07:44.873011Z"},"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T22:23:34.950796Z","iopub.execute_input":"2024-11-26T22:23:34.951379Z","iopub.status.idle":"2024-11-26T22:23:34.956304Z","shell.execute_reply.started":"2024-11-26T22:23:34.951349Z","shell.execute_reply":"2024-11-26T22:23:34.955258Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data preparation","metadata":{}},{"cell_type":"markdown","source":"## Loading the dataset","metadata":{}},{"cell_type":"code","source":"# Path to the dataset\n\nDATA_DIR = '/kaggle/input/characters/data/train'","metadata":{"ExecuteTime":{"end_time":"2024-11-25T23:22:56.004275Z","start_time":"2024-11-25T23:22:55.999276Z"},"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T22:23:39.043904Z","iopub.execute_input":"2024-11-26T22:23:39.044573Z","iopub.status.idle":"2024-11-26T22:23:39.048368Z","shell.execute_reply.started":"2024-11-26T22:23:39.044541Z","shell.execute_reply":"2024-11-26T22:23:39.047402Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the dataset\nimages = []\nlabels = []\n\ndir = os.listdir(DATA_DIR)\nnum_samples = len(dir)\n\n# Loop through each folder in the dataset\nfor i, folder in enumerate(os.listdir(DATA_DIR)):\n    if((i + 1) % 5 == 0):\n        print(f\"{i + 1}/{num_samples}\")\n    folder_path = os.path.join(DATA_DIR, folder)\n    if os.path.isdir(folder_path):\n        # Extract the character label from the folder name (e.g., Sample001 -> '001')\n        label = folder[6:]  # Assuming 'SampleXXX' format\n\n        # Loop through each image in the folder\n        for image_file in os.listdir(folder_path):\n            image_path = os.path.join(folder_path, image_file)\n\n            # Read the image in grayscale\n            img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n            img = cv2.resize(img, (28, 28))\n\n            # Append image and label to the lists\n            images.append(img)\n            labels.append(label)\n\n# Convert lists to numpy arrays\nimages = np.array(images)\nlabels = np.array(labels)","metadata":{"ExecuteTime":{"end_time":"2024-11-25T23:23:20.341876Z","start_time":"2024-11-25T23:22:56.779223Z"},"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T22:23:42.353812Z","iopub.execute_input":"2024-11-26T22:23:42.354175Z","iopub.status.idle":"2024-11-26T22:31:12.212544Z","shell.execute_reply.started":"2024-11-26T22:23:42.354137Z","shell.execute_reply":"2024-11-26T22:31:12.211589Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Reshape the images to add a channel dimension (for grayscale images)\nimages = images.reshape(-1, 28, 28, 1)\n\n# Normalize pixel values to the range [0, 1]\nX = images / 255.0","metadata":{"ExecuteTime":{"end_time":"2024-11-25T23:23:20.452808Z","start_time":"2024-11-25T23:23:20.343877Z"},"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T22:31:53.547060Z","iopub.execute_input":"2024-11-26T22:31:53.547437Z","iopub.status.idle":"2024-11-26T22:31:53.653128Z","shell.execute_reply.started":"2024-11-26T22:31:53.547390Z","shell.execute_reply":"2024-11-26T22:31:53.652462Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Encode the labels using LabelEncoder\nlabel_encoder = LabelEncoder()\ny = label_encoder.fit_transform(labels)","metadata":{"ExecuteTime":{"end_time":"2024-11-25T23:23:20.483320Z","start_time":"2024-11-25T23:23:20.470298Z"},"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T22:32:01.338936Z","iopub.execute_input":"2024-11-26T22:32:01.339279Z","iopub.status.idle":"2024-11-26T22:32:01.347429Z","shell.execute_reply.started":"2024-11-26T22:32:01.339249Z","shell.execute_reply":"2024-11-26T22:32:01.346689Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(X[0].shape)\nnp.unique(y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T23:19:07.143300Z","iopub.execute_input":"2024-11-26T23:19:07.143654Z","iopub.status.idle":"2024-11-26T23:19:07.150945Z","shell.execute_reply.started":"2024-11-26T23:19:07.143625Z","shell.execute_reply":"2024-11-26T23:19:07.150126Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Check","metadata":{}},{"cell_type":"code","source":"# Select an image to visualize (e.g., the first image in the dataset)\nimage_index = 0\n\n# Extract the corresponding image from the dataset (use squeeze() to remove the extra channel dimension)\nimage_to_show = X[image_index].squeeze()\n\n# Display the image\nplt.imshow(image_to_show, cmap='gray')\nplt.title(f\"Label: {label_encoder.inverse_transform([y[image_index]])[0]}\")\nplt.axis('off')  # Turn off axis\nplt.show()","metadata":{"ExecuteTime":{"end_time":"2024-11-25T23:23:45.533477Z","start_time":"2024-11-25T23:23:45.438988Z"},"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T22:32:03.715135Z","iopub.execute_input":"2024-11-26T22:32:03.715544Z","iopub.status.idle":"2024-11-26T22:32:03.895932Z","shell.execute_reply.started":"2024-11-26T22:32:03.715512Z","shell.execute_reply":"2024-11-26T22:32:03.894957Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Parameter Tuning","metadata":{}},{"cell_type":"markdown","source":"## Bayesian Optimization\nusing Keras tuner","metadata":{}},{"cell_type":"code","source":"from keras_tuner import HyperModel, Objective\nimport tensorflow as tf\nfrom keras_tuner.tuners import BayesianOptimization","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T22:32:13.197675Z","iopub.execute_input":"2024-11-26T22:32:13.198024Z","iopub.status.idle":"2024-11-26T22:32:13.408124Z","shell.execute_reply.started":"2024-11-26T22:32:13.197994Z","shell.execute_reply":"2024-11-26T22:32:13.407425Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split the data into training and validation sets (80% train, 20% validation)\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T22:32:43.397537Z","iopub.execute_input":"2024-11-26T22:32:43.397900Z","iopub.status.idle":"2024-11-26T22:32:43.507953Z","shell.execute_reply.started":"2024-11-26T22:32:43.397870Z","shell.execute_reply":"2024-11-26T22:32:43.507218Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create the keras tuner model.\nclass CNNHyperModel(HyperModel):\n    \n    def build(self, hp):\n        model = keras.Sequential()\n        model.add(layers.InputLayer(input_shape=(28, 28, 1)))\n\n        # First convolutional layer\n        model.add(layers.Conv2D(\n            filters=64,\n            kernel_size=(3, 3),\n            activation='relu'\n        ))\n        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n\n        # Second convolutional layer\n        model.add(layers.Conv2D(\n            filters=hp.Int('filters_2', min_value=96, max_value=224),\n            kernel_size=(3, 3),\n            activation='relu'\n        ))\n        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n\n        # Flatten and Dense layer\n        model.add(layers.Flatten())\n        model.add(layers.Dense(\n            units=hp.Int('dense_units', min_value=256, max_value=512),\n            activation='relu'\n        ))\n\n        model.add(layers.Dropout(\n            rate=hp.Float('dropout_rate', min_value=0.15, max_value=0.3)\n        ))\n\n        # Output layer\n        model.add(layers.Dense(62, activation='softmax'))  # Assuming 62 classes for character classification\n\n        # Compile the model\n        optimizer_instance = keras.optimizers.Adam(\n            learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n        )\n\n        # Compile the model\n        model.compile(\n            optimizer='adam',\n            loss='sparse_categorical_crossentropy',  # Use sparse categorical crossentropy for integer labels\n            metrics=['accuracy']\n        )\n\n        return model\n\nclass MyTuner(BayesianOptimization):\n    def __init__(self, *args, **kwargs):\n        super(MyTuner, self).__init__(*args, **kwargs)\n    def run_trial(self, trial, *args, **kwargs):\n        # You can add additional HyperParameters for preprocessing and custom training loops\n        # via overriding `run_trial`\n        kwargs['batch_size'] = trial.hyperparameters.Int('batch_size', 80, 144)\n        return super(MyTuner, self).run_trial(trial, *args, **kwargs)\n      ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T22:32:53.564779Z","iopub.execute_input":"2024-11-26T22:32:53.565591Z","iopub.status.idle":"2024-11-26T22:32:53.574338Z","shell.execute_reply.started":"2024-11-26T22:32:53.565559Z","shell.execute_reply":"2024-11-26T22:32:53.573474Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Bayesian Optimization using KerasTuner\ntuner = MyTuner(\n    CNNHyperModel(),\n    objective='val_accuracy',  # Optimize for validation accuracy\n    max_trials=10,  # Number of trials to run\n    executions_per_trial=2,  # Number of executions for each trial\n    directory='kt_search4',  # Directory to store the results\n    project_name='cnn_bayesian_optimization'  # Project name\n)\n\nes = keras.callbacks.EarlyStopping(\n    monitor=\"val_loss\",\n    min_delta=0,\n    patience=0,\n    verbose=1,\n    mode=\"auto\",\n    baseline=None,\n    restore_best_weights=False,\n    start_from_epoch=0,\n)\n\ntuner.search(\n    X_train, y_train,\n    epochs=15,\n    batch_size=64,\n    validation_data=(X_val, y_val),\n    callbacks=[es]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get the best model and evaluate it\nbest_model = tuner.get_best_models(num_models=1)[0]\nbest_model.summary()\n\n# Evaluate the best model\nval_loss, val_acc = best_model.evaluate(X_val, y_val)\nprint(f\"Validation Accuracy: {val_acc}\")\n\n\nbest_trial = tuner.oracle.get_best_trials(num_trials=1)[0]\nprint(\"Optimal Hyperparameters:\")\nfor hp_name, value in best_trial.hyperparameters.values.items():\n    print(f\"{hp_name}: {value}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Cross Validation","metadata":{}},{"cell_type":"code","source":"n_splits = 7\n\nkf = KFold(n_splits=n_splits, shuffle=True, random_state=42)","metadata":{"ExecuteTime":{"end_time":"2024-11-25T23:27:17.962776Z","start_time":"2024-11-25T23:27:17.954776Z"},"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T22:41:47.601201Z","iopub.execute_input":"2024-11-26T22:41:47.601602Z","iopub.status.idle":"2024-11-26T22:41:47.606079Z","shell.execute_reply.started":"2024-11-26T22:41:47.601569Z","shell.execute_reply":"2024-11-26T22:41:47.605188Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_accuracies = []\noptimal_epochs = []\n\n# Loop through each split\nfor i, (train_index, val_index) in enumerate(kf.split(images)):\n    print(f\"------------ Fold {i + 1} / {n_splits} ------------\")\n\n    X_train, X_val = X[train_index], X[val_index]\n    y_train, y_val = y[train_index], y[val_index]\n\n    # Define the model\n    model = keras.Sequential([\n        layers.Input(shape=(28, 28, 1)),\n        \n        # First Convolutional Layer\n        layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n        layers.MaxPooling2D(pool_size=(2, 2)),\n    \n        # Second Convolutional Layer\n        layers.Conv2D(192, kernel_size=(3, 3), activation='relu'),\n        layers.MaxPooling2D(pool_size=(2, 2)),\n    \n        # Flatten the output to feed into Dense layers\n        layers.Flatten(),\n    \n        # Fully Connected Layer with Dropout\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.25),\n    \n        # Output Layer with Softmax activation for multi-class classification\n        layers.Dense(62, activation='softmax')\n    ])\n\n    # Compile the model\n    model.compile(optimizer='adam',\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n\n    early_stopping = keras.callbacks.EarlyStopping(monitor='val_accuracy', \n                               patience=3,  # Stop if no improvement in 3 epochs\n                               restore_best_weights=True)\n        \n    # Train the model\n    history = model.fit(X_train, y_train,\n                            epochs=30,\n                            batch_size=96,\n                            validation_data=(X_val, y_val),\n                            callbacks=[early_stopping],\n                            verbose=1)\n\n    val_accuracies.append(max(history.history['val_accuracy']))\n    optimal_epochs.append(len(history.history['val_accuracy']))\n    print(f\"Accuracy: {max(history.history['val_accuracy'])}\")","metadata":{"ExecuteTime":{"end_time":"2024-11-25T23:54:33.311659Z","start_time":"2024-11-25T23:51:39.194629Z"},"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T22:47:12.465819Z","iopub.execute_input":"2024-11-26T22:47:12.466180Z","iopub.status.idle":"2024-11-26T22:51:15.482020Z","shell.execute_reply.started":"2024-11-26T22:47:12.466147Z","shell.execute_reply":"2024-11-26T22:51:15.481096Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"average_val_accuracy = np.mean(val_accuracies)\nprint(f'Average validation accuracy: {average_val_accuracy}')\n\naverage_optimal_epochs = int(sum(optimal_epochs) / len(optimal_epochs))\nprint(f\"Average Optimal Epochs: {average_optimal_epochs}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T22:51:24.121685Z","iopub.execute_input":"2024-11-26T22:51:24.122578Z","iopub.status.idle":"2024-11-26T22:51:24.127518Z","shell.execute_reply.started":"2024-11-26T22:51:24.122542Z","shell.execute_reply":"2024-11-26T22:51:24.126632Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"final_model = keras.Sequential([\n    layers.Input(shape=(28, 28, 1)),\n    \n    # First Convolutional Layer\n    layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n\n    # Second Convolutional Layer\n    layers.Conv2D(192, kernel_size=(3, 3), activation='relu'),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n\n    # Flatten the output to feed into Dense layers\n    layers.Flatten(),\n\n    # Fully Connected Layer with Dropout\n    layers.Dense(512, activation='relu'),\n    layers.Dropout(0.25),\n\n    # Output Layer with Softmax activation for multi-class classification\n    layers.Dense(62, activation='softmax')\n])\n\n# Compile the model\nfinal_model.compile(optimizer='adam',\n                    loss='sparse_categorical_crossentropy',\n                    metrics=['accuracy'])\n\n# Train the model\nfinal_model.fit(X, y,\n                epochs=average_optimal_epochs,\n                batch_size=96,\n                verbose=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T22:53:25.916526Z","iopub.execute_input":"2024-11-26T22:53:25.917237Z","iopub.status.idle":"2024-11-26T22:54:02.331845Z","shell.execute_reply.started":"2024-11-26T22:53:25.917200Z","shell.execute_reply":"2024-11-26T22:54:02.330970Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"test_folder_path = '/kaggle/input/characters/data/test'  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T23:12:58.850360Z","iopub.execute_input":"2024-11-26T23:12:58.850720Z","iopub.status.idle":"2024-11-26T23:12:58.854747Z","shell.execute_reply.started":"2024-11-26T23:12:58.850692Z","shell.execute_reply":"2024-11-26T23:12:58.853870Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_images = []\ntest_labels = []\n\n\ndir = os.listdir(test_folder_path)\nnum_samples = len(dir)\n\nfor i, image_file in enumerate(os.listdir(test_folder_path)):\n    if((i + 1) % 5 == 0):\n        print(f\"{i + 1}/{num_samples}\")\n\n    image_path = os.path.join(test_folder_path, image_file)\n\n    # Read the image in grayscale\n    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n\n    # Resize the image to 28x28\n    img = cv2.resize(img, (28, 28))\n\n    # Append image and label to the lists\n    test_images.append(img)\n    test_labels.append(image_file)\n\n# Convert lists to numpy arrays\ntest_images = np.array(test_images)\n\n# Reshape the images to add a channel dimension (for grayscale images)\ntest_images = test_images.reshape(-1, 28, 28, 1)\n\n# Normalize pixel values to the range [0, 1]\ntest_images = test_images / 255.0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T23:12:59.564107Z","iopub.execute_input":"2024-11-26T23:12:59.564465Z","iopub.status.idle":"2024-11-26T23:14:04.779920Z","shell.execute_reply.started":"2024-11-26T23:12:59.564435Z","shell.execute_reply":"2024-11-26T23:14:04.779141Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_pred = final_model.predict(test_images)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T23:24:07.860490Z","iopub.execute_input":"2024-11-26T23:24:07.860864Z","iopub.status.idle":"2024-11-26T23:24:08.924453Z","shell.execute_reply.started":"2024-11-26T23:24:07.860832Z","shell.execute_reply":"2024-11-26T23:24:08.923685Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_pred.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T23:26:18.641850Z","iopub.execute_input":"2024-11-26T23:26:18.642767Z","iopub.status.idle":"2024-11-26T23:26:18.649064Z","shell.execute_reply.started":"2024-11-26T23:26:18.642717Z","shell.execute_reply":"2024-11-26T23:26:18.648020Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open('submission.txt', 'w') as f:\n    for i in range(len(test_images)):\n        \n        predicted_class = np.argmax(test_pred[i]) + 1\n        label = test_labels[i]\n        \n        f.write(f\"{predicted_class};{label}\\n\")\n\nprint(\"Predictions saved to 'submission.txt'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T23:27:20.498913Z","iopub.execute_input":"2024-11-26T23:27:20.499787Z","iopub.status.idle":"2024-11-26T23:27:20.523176Z","shell.execute_reply.started":"2024-11-26T23:27:20.499737Z","shell.execute_reply":"2024-11-26T23:27:20.522434Z"}},"outputs":[],"execution_count":null}]}